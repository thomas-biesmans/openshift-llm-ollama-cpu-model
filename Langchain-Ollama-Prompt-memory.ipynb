{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## Example of querying the Ollama Inference server with Mistral-7b, Langchain and a custom Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a9bb1-b06e-4569-b1cf-c7cdcd65b5d9",
   "metadata": {},
   "source": [
    "### Set the Inference server url (replace with your own address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b28afc8-7a57-4c81-a0de-3fdb6270830d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server_url = \"https://ollama-<project>.apps.<cluster fqdn>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573f094-019a-4ab2-ad2f-ddf09c09b428",
   "metadata": {},
   "source": [
    "## Install and load requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx[http2] in /opt/app-root/lib/python3.9/site-packages (0.27.0)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (1.3.1)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/app-root/lib/python3.9/site-packages (from httpx[http2]) (4.1.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib/python3.9/site-packages (from httpcore==1.*->httpx[http2]) (0.14.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/app-root/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/app-root/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]) (4.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from anyio->httpx[http2]) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/app-root/lib/python3.9/site-packages (from anyio->httpx[http2]) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.1.14 requests\n",
    "!pip install httpx[http2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        response = requests.post(\n",
      "            verify=False,\n",
      "            url=api_url,\n"
     ]
    }
   ],
   "source": [
    "# SSL verification bypass\n",
    "!sed -i ':a;N;$!ba;s/response = requests.post(\\n            url/response = requests.post(\\n            verify=False,\\n            url/g' /opt/app-root/lib64/python3.9/site-packages/langchain_community/llms/ollama.py\n",
    "!cat /opt/app-root/lib64/python3.9/site-packages/langchain_community/llms/ollama.py | grep -A2 -B1 'response = req'\n",
    "\n",
    "# Imports\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import requests\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "import httpx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c0cbc-cea5-43a3-8483-4037626e4689",
   "metadata": {},
   "source": [
    "## Initiate model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0e062e-e368-420c-bc7c-868e1004d2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model pull on https://ollama-test-ai-llm-ollama-cpu-model.apps.rdlopenshiftvm.rdlabo.local/api/pull\n",
      "Streaming response:\n",
      "{\"status\":\"pulling manifest\"}\n",
      "\n",
      "{\"status\":\"pulling ff82381e2bea\",\"digest\":\"sha256:ff82381e2bea77d91c1b824c7afb83f6fb73e9f7de9dda631bcdbca564aa5435\",\"total\":4113289152,\"completed\":4113289152}\n",
      "{\"status\":\"pulling 43070e2d4e53\",\"digest\":\"sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1\",\"total\":11356,\"completed\":11356}\n",
      "{\"status\":\"pulling c43332387573\",\"digest\":\"sha256:c43332387573e98fdfad4a606171279955b53d891ba2500552c2984a6560ffb4\",\"total\":67,\"completed\":67}\n",
      "{\"status\":\"pulling ed11eda7790d\",\"digest\":\"sha256:ed11eda7790d05b49395598a42b155812b17e263214292f7b87d15e14003d337\",\"total\":30,\"completed\":30}\n",
      "{\"status\":\"pulling 42347cd80dc8\",\"digest\":\"sha256:42347cd80dc868877d2807869c0e9c90034392b2f1f001cae1563488021e2e19\",\"total\":485,\"completed\":485}\n",
      "\n",
      "{\"status\":\"verifying sha256 digest\"}\n",
      "\n",
      "{\"status\":\"writing manifest\"}\n",
      "\n",
      "{\"status\":\"removing any unused layers\"}\n",
      "\n",
      "{\"status\":\"success\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cookies = {\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "data = {\n",
    "    'name': 'mistral'\n",
    "}\n",
    "url = inference_server_url+'/api/pull'\n",
    "print('Performing model pull on ' + url)\n",
    "response = requests.post(url,\n",
    "                         headers=headers,\n",
    "                         cookies=cookies,\n",
    "                         json=data,\n",
    "                         stream=True,\n",
    "                         verify=False)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Streaming response:\")\n",
    "    # Iterate over the response content in chunks\n",
    "    count = 0\n",
    "    for chunk in response.iter_content(chunk_size=1024):  # Adjust chunk size as needed\n",
    "        if chunk:  # filter out keep-alive new chunks\n",
    "            decoded_chunk = chunk.decode()  # Decode bytes to string for printing\n",
    "            count += 1\n",
    "            if count in range(10):\n",
    "                print(decoded_chunk)\n",
    "            elif count % 50 == 0:\n",
    "                print(decoded_chunk)\n",
    "            # Example filtering condition: only print lines containing the word \"error\"\n",
    "            elif \"completed\" not in decoded_chunk.lower():\n",
    "                print(decoded_chunk)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ebefd-9ad3-4e8c-b231-533242c0aea5",
   "metadata": {},
   "source": [
    "### Listing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc0a3a5-af0a-4603-b80b-558e0aac9a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing available local models on https://ollama-test-ai-llm-ollama-cpu-model.apps.rdlopenshiftvm.rdlabo.local/api/tags\n",
      "{\n",
      "    \"models\": [\n",
      "        {\n",
      "            \"name\": \"mistral:latest\",\n",
      "            \"model\": \"mistral:latest\",\n",
      "            \"modified_at\": \"2024-07-11T11:27:52.821212724Z\",\n",
      "            \"size\": 4113301090,\n",
      "            \"digest\": \"2ae6f6dd7a3dd734790bbbf58b8909a606e0e7e97e94b7604e0aa7ae4490e6d8\",\n",
      "            \"details\": {\n",
      "                \"parent_model\": \"\",\n",
      "                \"format\": \"gguf\",\n",
      "                \"family\": \"llama\",\n",
      "                \"families\": [\n",
      "                    \"llama\"\n",
      "                ],\n",
      "                \"parameter_size\": \"7.2B\",\n",
      "                \"quantization_level\": \"Q4_0\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = inference_server_url+'/api/tags'\n",
    "print('Listing available local models on ' + url)\n",
    "response = requests.get(url,\n",
    "                        verify=False)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parsing the JSON response body\n",
    "    json_response = response.json()\n",
    "    \n",
    "    # Pretty printing the JSON object\n",
    "    import json\n",
    "    print(json.dumps(json_response, indent=4))\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "#### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = Ollama(\n",
    "    base_url=inference_server_url,\n",
    "    model=\"mistral\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    num_predict=512,\n",
    "    repeat_penalty=1.03,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211bd1f-3e55-41ce-b3bc-0ee5db689c66",
   "metadata": {},
   "source": [
    "#### Create the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd8bc4c-b353-4a51-a8b7-6cb348e19623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e36542-81a4-4eee-bcf8-f0dd5d9e3096",
   "metadata": {},
   "source": [
    "#### And finally some memory for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0005da7-1386-42a4-9d20-456c5dcca2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240fd72-f910-4ba4-82dc-c5ebf278452b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First example, fully verbose mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cb39d-1639-4713-8423-4ea4925ef6d1",
   "metadata": {},
   "source": [
    "#### Create the Chain using the different components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7998b5-4373-4b70-bd81-9617f7ff6bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=True,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969484f2-1f55-4021-a995-1d529cf9cc54",
   "metadata": {},
   "source": [
    "#### Let's talk..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      " Paris, the City of Light, is a vibrant metropolis renowned for its rich history, art, and culture. Known as the global center of fashion, gastronomy, and philosophy, it's home to iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Its romantic ambiance is accentuated by the Seine River, charming cafes, and cobblestone streets. Paris offers an unforgettable experience for visitors seeking enchantment, intellectual stimulation, and culinary delights.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "first_input = \"Describe Paris in 100 words or less.\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ed6c44-a016-49bd-8623-f231c5bba5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI:  Paris, the City of Light, is a vibrant metropolis renowned for its rich history, art, and culture. Known as the global center of fashion, gastronomy, and philosophy, it's home to iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Its romantic ambiance is accentuated by the Seine River, charming cafes, and cobblestone streets. Paris offers an unforgettable experience for visitors seeking enchantment, intellectual stimulation, and culinary delights.\n",
      "Human: Is there a river?\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      " Yes, the Seine River flows through Paris, adding to its charm and beauty. The riverbanks are lined with many famous landmarks, such as the Louvre Museum and Notre-Dame Cathedral, and offer beautiful views of the city.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This is a follow-up question without context to showcase the conversation memory\n",
    "second_input = \"Is there a river?\"\n",
    "conversation.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dd8b1-c5a1-41fd-8c7f-61e221360753",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Second example, no verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "842e0ab2-a061-4ebd-af71-7305c54af940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation2 = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=False,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60769ba-dd7a-4ac7-911a-3e0abe9e1732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's clear the previous conversation first\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9113c36-db08-464c-a6a7-e8fdf1068c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " London, the capital city of England and the United Kingdom, is a vibrant, historic, and cosmopolitan metropolis. Known for its iconic landmarks like the Tower of London, Buckingham Palace, and the London Eye, it's a city steeped in rich history. The River Thames, flowing through its heart, offers stunning views of the city's architecture, from modern skyscrapers to ancient buildings. London's cultural scene is diverse and dynamic, with world-class museums, galleries, and theaters. It's a global hub for finance, arts, fashion, and media, attracting millions of visitors each year. Despite its bustling urban landscape, London also boasts numerous parks and green spaces, providing a tranquil escape from the city's hustle and bustle."
     ]
    }
   ],
   "source": [
    "first_input = \"Can you describe London in 100 words?\"\n",
    "conversation2.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d618b39d-0e45-4147-b7c7-63f9f195c805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, the River Thames flows through London. It is one of the most famous rivers in Europe and plays a significant role in the city's history and daily life."
     ]
    }
   ],
   "source": [
    "# This is a follow-up question without context to showcase the conversation memory\n",
    "second_input = \"Is there a river?\"\n",
    "conversation2.predict(input=second_input);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
